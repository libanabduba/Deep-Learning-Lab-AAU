{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/libanabduba/Deep-Learning-Lab-AAU/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PKuE5D1Z6hZ8"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    self.weight = 0.01 * torch.rand((n_neurons,n_inputs))\n",
        "    self.bias = torch.zeros((1,n_neurons))\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    self.output = torch.matmul(inputs, self.weight.T) + self.bias\n",
        "\n",
        "    return self.output"
      ],
      "metadata": {
        "id": "7WBXyxhzCLvu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationReLU:\n",
        "    def forward(self, inputs):\n",
        "        # Calculate output values from inputs\n",
        "        self.output = torch.max(torch.tensor(0), inputs)\n",
        "        return self.output\n"
      ],
      "metadata": {
        "id": "LNxoxJZNCmZs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationSoftmax:\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Get unnormalized probabilities\n",
        "        exp_values = torch.exp(inputs - torch.max(inputs, axis=1, keepdim=True).values)\n",
        "        # Normalize them for each sample\n",
        "        probabilities = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "        self.output = probabilities\n",
        "        return self.output\n"
      ],
      "metadata": {
        "id": "QOsZfpDO33Wy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationSigmoid:\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Calculate sigmoid activation\n",
        "        sigmoid_values = 1 / (1 + torch.exp(-inputs))\n",
        "        self.output = sigmoid_values\n",
        "        return self.output"
      ],
      "metadata": {
        "id": "Rld3YqDo48LS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(softmax_outputs, class_targets):\n",
        "    # Calculate values along the second axis (axis of index 1)\n",
        "    predictions = torch.argmax(softmax_outputs, dim=1)\n",
        "\n",
        "    # If targets are one-hot encoded - convert them\n",
        "    if len(class_targets.shape) == 2:\n",
        "        class_targets = torch.argmax(class_targets, dim=1)\n",
        "\n",
        "    # True evaluates to 1; False to 0\n",
        "    accuracy = torch.mean((predictions == class_targets).float())\n",
        "\n",
        "    return accuracy.item()"
      ],
      "metadata": {
        "id": "BCdxPSWx6U_H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss_CategoricalCrossentropy():\n",
        "\n",
        "    def calculate(self, output, y):\n",
        "        # Calculate sample losses\n",
        "        sample_losses = self.forward(output, y)\n",
        "        # Calculate mean loss\n",
        "        data_loss = torch.mean(sample_losses)\n",
        "        # Return loss\n",
        "        return data_loss.item()\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # Number of samples in a batch\n",
        "        samples = y_pred.size(0)\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = torch.clamp(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Probabilities for target values -\n",
        "        # only if categorical labels\n",
        "        if len(y_true.size()) == 1:\n",
        "            correct_confidences = y_pred_clipped[\n",
        "                torch.arange(samples),\n",
        "                y_true\n",
        "            ]\n",
        "        # Mask values - only for one-hot encoded labels\n",
        "        elif len(y_true.size()) == 2:\n",
        "            correct_confidences = torch.sum(\n",
        "                y_pred_clipped * y_true,\n",
        "                dim=1\n",
        "            )\n",
        "\n",
        "        # Losses\n",
        "        negative_log_likelihoods = -torch.log(correct_confidences)\n",
        "        return negative_log_likelihoods"
      ],
      "metadata": {
        "id": "1dzasgHv6sJJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.rand(6, 4)\n",
        "inputs\n",
        "\n",
        "class_targets = torch.tensor([[0,1,1]])\n",
        "\n",
        "y = torch.rand(6,3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-hM6lRh581NW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layers\n",
        "\n",
        "layer1 =  DenseLayer(4, 18)\n",
        "layer2 = DenseLayer(18,18)\n",
        "layer3 = DenseLayer(18,18)\n",
        "output_layer = DenseLayer(18, 3)\n",
        "\n",
        "# Activation functions\n",
        "relu = ActivationReLU()\n",
        "sigmoid = ActivationSigmoid()\n",
        "softmax = ActivationSoftmax()\n",
        "\n",
        "# loss function\n",
        "loss_function = Loss_CategoricalCrossentropy()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LOxXqeDy9tWP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass - use ReLU on Hidden layers\n",
        "output1 = layer1.forward(inputs)\n",
        "\n",
        "output1_relu = relu.forward(output1)\n",
        "\n",
        "\n",
        "output2 = layer2.forward(output1_relu)\n",
        "\n",
        "output2_relu = relu.forward(output2)\n",
        "\n",
        "output3 = layer3.forward(output2_relu)\n",
        "\n",
        "output3_relu = relu.forward(output3)\n",
        "\n",
        "\n",
        "\n",
        "final_output = output_layer.forward(output3_relu)\n",
        "# print(final_output)\n",
        "final_softmax = softmax.forward(final_output)\n",
        "\n",
        "print(final_softmax)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SR4LasCN-ORq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f50976-7002-4a38-da2f-d5c630a881db"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333],\n",
            "        [0.3333, 0.3333, 0.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_function.calculate(final_softmax, y)\n",
        "\n",
        "accuracy = calculate_accuracy(final_softmax, class_targets)\n",
        "\n",
        "print(f\"loss: {loss}\")\n",
        "print(f\"accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTuzhO-2-laz",
        "outputId": "23478771-fd51-4c07-8653-21983b76c12b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.5602917671203613\n",
            "accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass - use Sigmoid on Hidden layers\n",
        "\n",
        "output1 = layer1.forward(inputs)\n",
        "\n",
        "output1_sigmoid = sigmoid.forward(output1)\n",
        "\n",
        "\n",
        "output2 = layer2.forward(output1_sigmoid)\n",
        "\n",
        "output2_sigmoid = sigmoid.forward(output2)\n",
        "\n",
        "output3 = layer3.forward(output2_sigmoid)\n",
        "\n",
        "output3_sigmoid = sigmoid.forward(output3)\n",
        "\n",
        "\n",
        "\n",
        "final_output = output_layer.forward(output3_sigmoid)\n",
        "# print(final_output)\n",
        "final_softmax = softmax.forward(final_output)\n",
        "\n",
        "print(final_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IvBLfkxkosb",
        "outputId": "54f05284-16da-4ea7-c6a9-e33bc4d58a59"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3343, 0.3323, 0.3334],\n",
            "        [0.3343, 0.3323, 0.3334],\n",
            "        [0.3343, 0.3323, 0.3334],\n",
            "        [0.3343, 0.3323, 0.3334],\n",
            "        [0.3343, 0.3323, 0.3334],\n",
            "        [0.3343, 0.3323, 0.3334]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_function.calculate(final_softmax, y)\n",
        "\n",
        "accuracy = calculate_accuracy(final_softmax, class_targets)\n",
        "\n",
        "print(f\"loss: {loss}\")\n",
        "print(f\"accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxZ4ajXJlyA2",
        "outputId": "b40b4546-0cb1-4b41-d664-cde95bfbbaaf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 0.5598424673080444\n",
            "accuracy: 0.0\n"
          ]
        }
      ]
    }
  ]
}